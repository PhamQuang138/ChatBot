{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 654,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.045871559633027525,
      "grad_norm": 18.898433685302734,
      "learning_rate": 4.5e-05,
      "loss": 5.6348,
      "step": 10
    },
    {
      "epoch": 0.09174311926605505,
      "grad_norm": 0.600585401058197,
      "learning_rate": 9.5e-05,
      "loss": 0.594,
      "step": 20
    },
    {
      "epoch": 0.13761467889908258,
      "grad_norm": 0.5402803421020508,
      "learning_rate": 9.995028650728336e-05,
      "loss": 0.4399,
      "step": 30
    },
    {
      "epoch": 0.1834862385321101,
      "grad_norm": 1.159772276878357,
      "learning_rate": 9.977856431060221e-05,
      "loss": 0.408,
      "step": 40
    },
    {
      "epoch": 0.22935779816513763,
      "grad_norm": 0.7106755971908569,
      "learning_rate": 9.948464112207811e-05,
      "loss": 0.3462,
      "step": 50
    },
    {
      "epoch": 0.27522935779816515,
      "grad_norm": 0.43756699562072754,
      "learning_rate": 9.906923849135118e-05,
      "loss": 0.4215,
      "step": 60
    },
    {
      "epoch": 0.3211009174311927,
      "grad_norm": 0.693917453289032,
      "learning_rate": 9.853337618695413e-05,
      "loss": 0.3826,
      "step": 70
    },
    {
      "epoch": 0.3669724770642202,
      "grad_norm": 0.6813252568244934,
      "learning_rate": 9.78783696928909e-05,
      "loss": 0.2778,
      "step": 80
    },
    {
      "epoch": 0.41284403669724773,
      "grad_norm": 0.7801543474197388,
      "learning_rate": 9.710582697926561e-05,
      "loss": 0.3451,
      "step": 90
    },
    {
      "epoch": 0.45871559633027525,
      "grad_norm": 0.665168821811676,
      "learning_rate": 9.621764455488991e-05,
      "loss": 0.2833,
      "step": 100
    },
    {
      "epoch": 0.5045871559633027,
      "grad_norm": 0.7956693172454834,
      "learning_rate": 9.521600281155893e-05,
      "loss": 0.3565,
      "step": 110
    },
    {
      "epoch": 0.5504587155963303,
      "grad_norm": 0.7683166861534119,
      "learning_rate": 9.410336067142524e-05,
      "loss": 0.3587,
      "step": 120
    },
    {
      "epoch": 0.5963302752293578,
      "grad_norm": 0.5588508248329163,
      "learning_rate": 9.28824495506109e-05,
      "loss": 0.3432,
      "step": 130
    },
    {
      "epoch": 0.6422018348623854,
      "grad_norm": 0.5532282590866089,
      "learning_rate": 9.155626665387624e-05,
      "loss": 0.2352,
      "step": 140
    },
    {
      "epoch": 0.6880733944954128,
      "grad_norm": 1.0652955770492554,
      "learning_rate": 9.012806761680642e-05,
      "loss": 0.2967,
      "step": 150
    },
    {
      "epoch": 0.7339449541284404,
      "grad_norm": 0.6003366708755493,
      "learning_rate": 8.860135851357804e-05,
      "loss": 0.2283,
      "step": 160
    },
    {
      "epoch": 0.7798165137614679,
      "grad_norm": 0.793834924697876,
      "learning_rate": 8.697988724992633e-05,
      "loss": 0.2313,
      "step": 170
    },
    {
      "epoch": 0.8256880733944955,
      "grad_norm": 0.5246009826660156,
      "learning_rate": 8.526763436244183e-05,
      "loss": 0.24,
      "step": 180
    },
    {
      "epoch": 0.8715596330275229,
      "grad_norm": 0.6144527196884155,
      "learning_rate": 8.346880324678358e-05,
      "loss": 0.2321,
      "step": 190
    },
    {
      "epoch": 0.9174311926605505,
      "grad_norm": 1.0730229616165161,
      "learning_rate": 8.158780983879737e-05,
      "loss": 0.3151,
      "step": 200
    },
    {
      "epoch": 0.963302752293578,
      "grad_norm": 1.1966816186904907,
      "learning_rate": 7.962927177387086e-05,
      "loss": 0.309,
      "step": 210
    },
    {
      "epoch": 1.0091743119266054,
      "grad_norm": 0.7290883660316467,
      "learning_rate": 7.759799705113798e-05,
      "loss": 0.3128,
      "step": 220
    },
    {
      "epoch": 1.0550458715596331,
      "grad_norm": 0.6292601227760315,
      "learning_rate": 7.54989722303612e-05,
      "loss": 0.2859,
      "step": 230
    },
    {
      "epoch": 1.1009174311926606,
      "grad_norm": 0.3349372446537018,
      "learning_rate": 7.33373501904665e-05,
      "loss": 0.2355,
      "step": 240
    },
    {
      "epoch": 1.146788990825688,
      "grad_norm": 0.49671563506126404,
      "learning_rate": 7.111843747978296e-05,
      "loss": 0.2539,
      "step": 250
    },
    {
      "epoch": 1.1926605504587156,
      "grad_norm": 0.9096325635910034,
      "learning_rate": 6.884768128904037e-05,
      "loss": 0.2531,
      "step": 260
    },
    {
      "epoch": 1.238532110091743,
      "grad_norm": 0.2806883454322815,
      "learning_rate": 6.653065607910535e-05,
      "loss": 0.2129,
      "step": 270
    },
    {
      "epoch": 1.2844036697247707,
      "grad_norm": 0.7442122101783752,
      "learning_rate": 6.417304989628252e-05,
      "loss": 0.2916,
      "step": 280
    },
    {
      "epoch": 1.3302752293577982,
      "grad_norm": 1.170249581336975,
      "learning_rate": 6.17806504087762e-05,
      "loss": 0.2593,
      "step": 290
    },
    {
      "epoch": 1.3761467889908257,
      "grad_norm": 0.6361333131790161,
      "learning_rate": 5.935933069859083e-05,
      "loss": 0.2121,
      "step": 300
    },
    {
      "epoch": 1.4220183486238533,
      "grad_norm": 0.5946778059005737,
      "learning_rate": 5.691503484374974e-05,
      "loss": 0.2673,
      "step": 310
    },
    {
      "epoch": 1.4678899082568808,
      "grad_norm": 0.6212623119354248,
      "learning_rate": 5.4453763326226556e-05,
      "loss": 0.2055,
      "step": 320
    },
    {
      "epoch": 1.5137614678899083,
      "grad_norm": 0.47606557607650757,
      "learning_rate": 5.19815583014109e-05,
      "loss": 0.2424,
      "step": 330
    },
    {
      "epoch": 1.5596330275229358,
      "grad_norm": 1.4660003185272217,
      "learning_rate": 4.9504488765270355e-05,
      "loss": 0.3054,
      "step": 340
    },
    {
      "epoch": 1.6055045871559632,
      "grad_norm": 1.0317728519439697,
      "learning_rate": 4.7028635655621636e-05,
      "loss": 0.243,
      "step": 350
    },
    {
      "epoch": 1.6513761467889907,
      "grad_norm": 0.7243334054946899,
      "learning_rate": 4.456007692408603e-05,
      "loss": 0.2121,
      "step": 360
    },
    {
      "epoch": 1.6972477064220184,
      "grad_norm": 0.33857035636901855,
      "learning_rate": 4.210487261537545e-05,
      "loss": 0.1752,
      "step": 370
    },
    {
      "epoch": 1.7431192660550459,
      "grad_norm": 0.5778573155403137,
      "learning_rate": 3.966904999053802e-05,
      "loss": 0.2347,
      "step": 380
    },
    {
      "epoch": 1.7889908256880735,
      "grad_norm": 0.6664775013923645,
      "learning_rate": 3.72585887306841e-05,
      "loss": 0.1915,
      "step": 390
    },
    {
      "epoch": 1.834862385321101,
      "grad_norm": 0.6541039347648621,
      "learning_rate": 3.4879406257515844e-05,
      "loss": 0.2957,
      "step": 400
    },
    {
      "epoch": 1.8807339449541285,
      "grad_norm": 0.6867710947990417,
      "learning_rate": 3.253734320669686e-05,
      "loss": 0.2487,
      "step": 410
    },
    {
      "epoch": 1.926605504587156,
      "grad_norm": 1.5465542078018188,
      "learning_rate": 3.0238149089723356e-05,
      "loss": 0.306,
      "step": 420
    },
    {
      "epoch": 1.9724770642201834,
      "grad_norm": 0.9175851941108704,
      "learning_rate": 2.7987468179495235e-05,
      "loss": 0.2122,
      "step": 430
    },
    {
      "epoch": 2.018348623853211,
      "grad_norm": 0.5993762016296387,
      "learning_rate": 2.5790825654236504e-05,
      "loss": 0.1828,
      "step": 440
    },
    {
      "epoch": 2.0642201834862384,
      "grad_norm": 0.5498242974281311,
      "learning_rate": 2.365361403378034e-05,
      "loss": 0.1676,
      "step": 450
    },
    {
      "epoch": 2.1100917431192663,
      "grad_norm": 0.8835911750793457,
      "learning_rate": 2.158107994151602e-05,
      "loss": 0.2565,
      "step": 460
    },
    {
      "epoch": 2.1559633027522938,
      "grad_norm": 0.9206545948982239,
      "learning_rate": 1.9578311224496032e-05,
      "loss": 0.1747,
      "step": 470
    },
    {
      "epoch": 2.2018348623853212,
      "grad_norm": 0.6488797664642334,
      "learning_rate": 1.7650224463321674e-05,
      "loss": 0.2502,
      "step": 480
    },
    {
      "epoch": 2.2477064220183487,
      "grad_norm": 1.3840038776397705,
      "learning_rate": 1.580155290246957e-05,
      "loss": 0.235,
      "step": 490
    },
    {
      "epoch": 2.293577981651376,
      "grad_norm": 1.1824703216552734,
      "learning_rate": 1.4036834830688161e-05,
      "loss": 0.2085,
      "step": 500
    },
    {
      "epoch": 2.3394495412844036,
      "grad_norm": 0.7869436740875244,
      "learning_rate": 1.2360402439989899e-05,
      "loss": 0.1763,
      "step": 510
    },
    {
      "epoch": 2.385321100917431,
      "grad_norm": 0.5991413593292236,
      "learning_rate": 1.0776371190588164e-05,
      "loss": 0.1964,
      "step": 520
    },
    {
      "epoch": 2.4311926605504586,
      "grad_norm": 0.7917006015777588,
      "learning_rate": 9.288629707887669e-06,
      "loss": 0.2275,
      "step": 530
    },
    {
      "epoch": 2.477064220183486,
      "grad_norm": 0.9032511711120605,
      "learning_rate": 7.900830236329537e-06,
      "loss": 0.1867,
      "step": 540
    },
    {
      "epoch": 2.522935779816514,
      "grad_norm": 1.0470210313796997,
      "learning_rate": 6.6163796735263015e-06,
      "loss": 0.1928,
      "step": 550
    },
    {
      "epoch": 2.5688073394495414,
      "grad_norm": 0.5778465270996094,
      "learning_rate": 5.438431206696598e-06,
      "loss": 0.1941,
      "step": 560
    },
    {
      "epoch": 2.614678899082569,
      "grad_norm": 0.6332894563674927,
      "learning_rate": 4.3698765719316915e-06,
      "loss": 0.192,
      "step": 570
    },
    {
      "epoch": 2.6605504587155964,
      "grad_norm": 0.8535288572311401,
      "learning_rate": 3.413338955295964e-06,
      "loss": 0.1734,
      "step": 580
    },
    {
      "epoch": 2.706422018348624,
      "grad_norm": 0.6793104410171509,
      "learning_rate": 2.5711665531889804e-06,
      "loss": 0.1664,
      "step": 590
    },
    {
      "epoch": 2.7522935779816513,
      "grad_norm": 0.7302584648132324,
      "learning_rate": 1.845426807777151e-06,
      "loss": 0.2387,
      "step": 600
    },
    {
      "epoch": 2.7981651376146788,
      "grad_norm": 0.9933071136474609,
      "learning_rate": 1.2379013316469012e-06,
      "loss": 0.1925,
      "step": 610
    },
    {
      "epoch": 2.8440366972477067,
      "grad_norm": 0.6562976837158203,
      "learning_rate": 7.50081534138386e-07,
      "loss": 0.1928,
      "step": 620
    },
    {
      "epoch": 2.8899082568807337,
      "grad_norm": 0.41170454025268555,
      "learning_rate": 3.8316496009691004e-07,
      "loss": 0.1986,
      "step": 630
    },
    {
      "epoch": 2.9357798165137616,
      "grad_norm": 0.7198394536972046,
      "learning_rate": 1.3805235002979922e-07,
      "loss": 0.1843,
      "step": 640
    },
    {
      "epoch": 2.981651376146789,
      "grad_norm": 0.6788535118103027,
      "learning_rate": 1.534542888590451e-08,
      "loss": 0.1716,
      "step": 650
    }
  ],
  "logging_steps": 10,
  "max_steps": 654,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3932919177412608.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
